{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny Parameter Selection Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The canny edge detector is an algorithm that is used to identify edges with in an image. There are three primary objectives the algorithm attempts to meet.\n",
    "\n",
    "1. Detection of edge with low error rate.\n",
    "2. The edge point detected from the operator should accurately localize on the center of the edge.\n",
    "3. A given edge in the image should ony be marked once.\n",
    "\n",
    "The canny edge dector performs the following operations.\n",
    "\n",
    "1. Apply Guassian filter to smooth the image in order to remove the noise.\n",
    "2. Find the intensity gradients of the image.\n",
    "3. Apply non-maximum suppression to get rid of spurious response to edge detection.\n",
    "4. Apply double threshold to determine potential edges.\n",
    "5. Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n",
    "\n",
    "### Guassian Filter\n",
    "\n",
    "**Filters image noise.**\n",
    "\n",
    "It is important to understand that the selection of the size of the Gaussian kernel will affect the performance of the detector. The larger the size is, the lower the detector’s sensitivity to noise. Additionally, the localization error to detect the edge will slightly increase with the increase of the Gaussian filter kernel size. A 5×5 is a good size for most cases, but this will also vary depending on specific situations.\n",
    "\n",
    "### Finding the intensity gradient of the image\n",
    "\n",
    "**Four filters are used to detect horizontal, vertical, and diagonal edges in the blurred image.** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "canny_params = dict()\n",
    "canny_params['low_threshold'] = 75\n",
    "canny_params['high_threshold'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/solidWhiteCurve.jpg')\n",
    "\n",
    "# convert image to grayscale\n",
    "gray = grayscale(img)\n",
    "\n",
    "# blur image\n",
    "blur = gaussian_blur(gray, kernel_size=5)\n",
    "\n",
    "# find edges\n",
    "edges = canny(blur, **canny_params)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(edges, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "\n",
    "# convert image to grayscale\n",
    "gray = grayscale(img)\n",
    "\n",
    "# blur image\n",
    "blur = gaussian_blur(gray, kernel_size=5)\n",
    "\n",
    "# find edges\n",
    "edges = canny(blur, **canny_params)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(edges, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/solidYellowCurve2.jpg')\n",
    "\n",
    "# convert image to grayscale\n",
    "gray = grayscale(img)\n",
    "\n",
    "# blur image\n",
    "blur = gaussian_blur(gray, kernel_size=5)\n",
    "\n",
    "# find edges\n",
    "edges = canny(blur, **canny_params)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(edges, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/solidYellowLeft.jpg')\n",
    "\n",
    "# convert image to grayscale\n",
    "gray = grayscale(img)\n",
    "\n",
    "# blur image\n",
    "blur = gaussian_blur(gray, kernel_size=5)\n",
    "\n",
    "# find edges\n",
    "edges = canny(blur, **canny_params)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(edges, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/whiteCarLaneSwitch.jpg')\n",
    "\n",
    "# convert image to grayscale\n",
    "gray = grayscale(img)\n",
    "\n",
    "# blur image\n",
    "blur = gaussian_blur(gray, kernel_size=5)\n",
    "\n",
    "# find edges\n",
    "edges = canny(blur, **canny_params)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(edges, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/solidYellowCurve.jpg')\n",
    "\n",
    "# convert image to grayscale\n",
    "gray = grayscale(img)\n",
    "\n",
    "# blur image\n",
    "blur = gaussian_blur(gray, kernel_size=5)\n",
    "\n",
    "# find edges\n",
    "edges = canny(blur, **canny_params)\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(edges, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial and Error Results\n",
    "\n",
    "It looks like a lower threshold of **75** and high threshold of **200** works best for these images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Interest Parameter Selection\n",
    "\n",
    "Time to find the best parameters for region selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find all image files\n",
    "img_dir = \"test_images/\"\n",
    "img_files = [os.path.join(img_dir, i) for i in os.listdir(img_dir)]\n",
    "for img_fp in img_files:\n",
    "    img = mpimg.imread(img_fp)\n",
    "    gray = grayscale(img)\n",
    "    blur = gaussian_blur(gray, kernel_size=5)\n",
    "    edges = canny(blur, low_threshold=75, high_threshold=200)\n",
    "    \n",
    "#     # center vertical line\n",
    "#     cv2.line(edges, (480, 0), (480, 540), color=[255, 0, 0], thickness=5)\n",
    "    \n",
    "#     # horizontal line\n",
    "#     cv2.line(edges, (0, 335), (960, 335), color=[255, 0, 0], thickness=5)\n",
    "    \n",
    "#     # left vertical line\n",
    "#     cv2.line(edges, (400, 335), (60, 540), color=[255, 0, 0], thickness=5)\n",
    "    \n",
    "#     # right vertical line\n",
    "#     cv2.line(edges, (560, 335), (960, 540), color=[255, 0, 0], thickness=5)\n",
    "    \n",
    "    verticies = np.array([[(400, 335), (60, 540), (960, 540), (560, 335)]])\n",
    "    region = region_of_interest(edges, vertices=verticies)\n",
    "    \n",
    "    # plot image\n",
    "    plt.figure()\n",
    "    plt.imshow(region, cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial and Error Results\n",
    "\n",
    "The best region I found was a trapezoid composed of the following points:\n",
    "\n",
    "* (400, 335) \n",
    "* (60, 540) \n",
    "* (960, 540) \n",
    "* (560, 335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_window = {'low': 60,\n",
    "            'high': 960}\n",
    "y_window = {'low': 335,\n",
    "            'high': 540}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hough Transform Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def process_image(img):\n",
    "    \"\"\"\n",
    "    This pipline includes grayscale, gaussian, edges, and region of interest with parameters identified above.\n",
    "    \"\"\"\n",
    "    gray = grayscale(img)\n",
    "    blur = gaussian_blur(gray, kernel_size=5)\n",
    "    edges = canny(blur, low_threshold=75, high_threshold=200)\n",
    "    verticies = np.array([[(400, 335), (60, 540), (960, 540), (560, 335)]])\n",
    "    region = region_of_interest(edges, vertices=verticies)\n",
    "    return region\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hough_params = {'rho': 1,\n",
    "                'theta': np.pi/180,\n",
    "                'threshold': 15,\n",
    "                'min_line_len': 15,\n",
    "                'max_line_gap': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"test_images/solidWhiteCurve.jpg\")\n",
    "region = process_image(img)\n",
    "lines = hough_lines(region, **hough_params)\n",
    "\n",
    "cv2.line(lines, (480,0), (480, 540), color=[255,0,0], thickness=5)\n",
    "\n",
    "plt.imshow(lines, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"test_images/solidWhiteRight.jpg\")\n",
    "region = process_image(img)\n",
    "lines = hough_lines(region, **hough_params)\n",
    "\n",
    "cv2.line(lines, (480,0), (480, 540), color=[255,0,0], thickness=5)\n",
    "\n",
    "plt.imshow(lines, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"test_images/solidYellowCurve.jpg\")\n",
    "region = process_image(img)\n",
    "lines = hough_lines(region, **hough_params)\n",
    "\n",
    "cv2.line(lines, (480,0), (480, 540), color=[255,0,0], thickness=5)\n",
    "\n",
    "plt.imshow(lines, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"test_images/solidYellowCurve2.jpg\")\n",
    "region = process_image(img)\n",
    "lines = hough_lines(region, **hough_params)\n",
    "\n",
    "cv2.line(lines, (480,0), (480, 540), color=[255,0,0], thickness=5)\n",
    "\n",
    "plt.imshow(lines, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"test_images/solidYellowLeft.jpg\")\n",
    "region = process_image(img)\n",
    "lines = hough_lines(region, **hough_params)\n",
    "\n",
    "cv2.line(lines, (480,0), (480, 540), color=[255,0,0], thickness=5)\n",
    "\n",
    "plt.imshow(lines, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"test_images/whiteCarLaneSwitch.jpg\")\n",
    "region = process_image(img)\n",
    "lines = hough_lines(region, **hough_params)\n",
    "\n",
    "cv2.line(lines, (480,0), (480, 540), color=[255,0,0], thickness=5)\n",
    "\n",
    "plt.imshow(lines, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope Analysis Given Hough Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_dir = \"test_images/\"\n",
    "img_files = [os.path.join(img_dir, i) for i in os.listdir(img_dir)]\n",
    "\n",
    "\n",
    "for img_fp in img_files:\n",
    "    slopes = []\n",
    "    lengths = []\n",
    "    \n",
    "    img = mpimg.imread(img_fp)\n",
    "    region = process_image(img)\n",
    "    lines = cv2.HoughLinesP(region, \n",
    "                                   hough_params['rho'], \n",
    "                                   hough_params['theta'], \n",
    "                                   hough_params['threshold'], \n",
    "                                   np.array([]), \n",
    "                                   minLineLength=hough_params['min_line_len'], \n",
    "                                   maxLineGap=hough_params['max_line_gap'])\n",
    "\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            slopes.append(slope)\n",
    "            \n",
    "            length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "            lengths.append(length)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(region, cmap=\"gray\")\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(slopes, lengths, 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Frame Analysis\n",
    "\n",
    "Need to make sure parameter selection is robust for all images in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image_final(img):\n",
    "    region = process_image(img)\n",
    "    lines = cv2.HoughLinesP(region, \n",
    "                            hough_params['rho'], \n",
    "                            hough_params['theta'], \n",
    "                            hough_params['threshold'], \n",
    "                            np.array([]), \n",
    "                            minLineLength=hough_params['min_line_len'], \n",
    "                            maxLineGap=hough_params['max_line_gap'])\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            dx = (x2 - x1)\n",
    "            dy = (y2 - y1)\n",
    "            slope = dy/dx\n",
    "            length = np.sqrt((dy)**2 + (dx)**2)\n",
    "            centroid = dx/2 + x1, dy/2 + y1\n",
    "            slopes.append(slope)\n",
    "            lengths.append(length)\n",
    "            centroids.append(centroid)    \n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:05<00:00, 38.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 14.9 s, sys: 516 ms, total: 15.4 s\n",
      "Wall time: 5.87 s\n"
     ]
    }
   ],
   "source": [
    "# reset data\n",
    "slopes = []\n",
    "lengths = []\n",
    "centroids = []\n",
    "\n",
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image_final) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "slopes_white = np.copy(np.array(slopes))\n",
    "lengths_white = np.copy(np.array(lengths))\n",
    "centroids_white = np.copy(np.array(centroids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(slopes_white, lengths_white, 'x')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(centroids_white[:,0], centroids_white[:,1], 'x')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:17<00:00, 38.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 46.2 s, sys: 1.6 s, total: 47.8 s\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "# reset data\n",
    "slopes = []\n",
    "lengths = []\n",
    "centroids = []\n",
    "\n",
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image_final)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "\n",
    "slopes_yellow = np.copy(np.array(slopes))\n",
    "lengths_yellow = np.copy(np.array(lengths))\n",
    "centroids_yellow = np.copy(np.array(centroids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(slopes_yellow, lengths_yellow, 'x')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(centroids_yellow[:,0], centroids_yellow[:,1], 'x')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(slopes_white, lengths_white, 'bx', slopes_yellow, lengths_yellow, 'ro')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(centroids_white[:,0], centroids_white[:,1], 'bx', centroids_yellow[:,0], centroids_yellow[:,1], 'ro')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "\n",
    "# concatenate and white and yellow data\n",
    "slopes = np.concatenate((slopes_white, slopes_yellow))\n",
    "lengths = np.concatenate((lengths_white, lengths_yellow))\n",
    "centroids = np.concatenate((centroids_white, centroids_yellow))\n",
    "\n",
    "# plot slopes and centroids\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(slopes, lengths, 'x')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(centroids[:,0], centroids[:,1], 'x')\n",
    "\n",
    "# split data between left and right side of image\n",
    "left, = np.where(centroids[:,0] < 480)\n",
    "right, = np.where(centroids[:,0] > 480)\n",
    "\n",
    "# slice left side of data\n",
    "sl = slopes[left]\n",
    "ll = lengths[left]\n",
    "cl = centroids[left, :]\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(sl, ll, 'x')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(cl[:,0], cl[:,1], 'x')\n",
    "\n",
    "# slice right side of data\n",
    "sr = slopes[right]\n",
    "lr = lengths[right]\n",
    "cr = centroids[right, :]\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(sr, lr, 'x')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(cr[:,0], cr[:,1], 'x')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_intercept = lambda y, slope, y_intercept: (y - y_intercept)/slope\n",
    "\n",
    "# left fit\n",
    "slope_left, intercept_left = np.polyfit(cl[:,0], cl[:,1], deg=1)\n",
    "xl_0 = x_intercept(y_window['low'], slope_left, intercept_left)\n",
    "xl_f = x_intercept(y_window['high'], slope_left, intercept_left)\n",
    "\n",
    "xl = np.linspace(xl_0, xl_f)\n",
    "left_line = np.poly1d((slope_left, intercept_left))\n",
    "\n",
    "# fit line to data\n",
    "plt.figure()\n",
    "plt.plot(cl[:,0], cl[:,1], 'x', xl, left_line(xl))\n",
    "\n",
    "# right fit\n",
    "slope_right, intercept_right = np.polyfit(cr[:,0], cr[:,1], deg=1)\n",
    "xr_0 = x_intercept(y_window['low'], slope_right, intercept_right)\n",
    "xr_f = x_intercept(y_window['high'], slope_right, intercept_right)\n",
    "\n",
    "xr = np.linspace(xr_0, xr_f)\n",
    "right_line = np.poly1d((slope_right, intercept_right))\n",
    "\n",
    "# fit line to data\n",
    "plt.figure()\n",
    "plt.plot(cr[:,0], cr[:,1], 'x', xr, right_line(xr))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distance_from_line(x, y, line, lower, upper):\n",
    "    \"\"\"\n",
    "    Compute delta x of point from line\n",
    "    \"\"\"\n",
    "    slope, intercept = line.coeffs\n",
    "    x_line = x_intercept(y, slope, intercept)\n",
    "    return x - x_line\n",
    "\n",
    "def centroids_in_bounds(data, lower_bound, upper_bound):\n",
    "    \"\"\"\n",
    "    Find centroids with y values in bound.\n",
    "    \"\"\"\n",
    "    lower = np.where(data[:,1] > lower_bound)\n",
    "    upper = np.where(data[:,1] < upper_bound)\n",
    "    in_bounds = np.intersect1d(lower, upper)\n",
    "    return data[in_bounds,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sectional Guassian Fit to Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "\n",
    "y_bin_size = 10\n",
    "y_bins = int(y_window['high']/y_bin_size - y_window['low']/y_bin_size)\n",
    "\n",
    "bounds = [[v, v + y_bin_size] for v in range(y_window['low'], y_window['high'], y_bin_size)]\n",
    "\n",
    "left_lookup = dict()\n",
    "for lower_bound, upper_bound in bounds:\n",
    "    key = (lower_bound, upper_bound)\n",
    "    points = centroids_in_bounds(cl, lower_bound=lower_bound, upper_bound=upper_bound)\n",
    "    distances = np.array([distance_from_line(p[0], p[1], left_line, lower_bound, upper_bound) for p in points])\n",
    "    left_lookup[key] = (np.mean(distances), np.std(distances))\n",
    "    \n",
    "yl = left_line(xl)\n",
    "xl_err = np.zeros_like(xl) \n",
    "for lower_bound, upper_bound in left_lookup:\n",
    "    for idx, y_value in enumerate(yl):\n",
    "        if lower_bound <= y_value <= upper_bound:\n",
    "            std = left_lookup[(lower_bound, upper_bound)][1]\n",
    "            xl_err[idx] = 2*std\n",
    "\n",
    "plt.plot(cl[:,0], cl[:,1], 'x')\n",
    "plt.errorbar(xl, yl, xerr=xl_err)\n",
    "    \n",
    "right_lookup = dict()\n",
    "for lower_bound, upper_bound in bounds:\n",
    "    key = (lower_bound, upper_bound)\n",
    "    points = centroids_in_bounds(cr, lower_bound=lower_bound, upper_bound=upper_bound)\n",
    "    distances = np.array([distance_from_line(p[0], p[1], right_line, lower_bound, upper_bound) for p in points])\n",
    "    right_lookup[key] = (np.mean(distances), np.std(distances))\n",
    "    \n",
    "yr = right_line(xr)\n",
    "xr_err = np.zeros_like(xr) \n",
    "for lower_bound, upper_bound in right_lookup:\n",
    "    for idx, y_value in enumerate(yr):\n",
    "        if lower_bound <= y_value <= upper_bound:\n",
    "            std = right_lookup[(lower_bound, upper_bound)][1]\n",
    "            xr_err[idx] = 2*std\n",
    "\n",
    "plt.plot(cr[:,0], cr[:,1], 'x')\n",
    "plt.errorbar(xr, yr, xerr=xr_err)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,1,2)\n",
    "\n",
    "not_outliers = []\n",
    "for lower_bound, upper_bound in bounds:\n",
    "    for idx, point in enumerate(cl):\n",
    "        x, y = point\n",
    "        if lower_bound <= y <= upper_bound:\n",
    "            d = distance_from_line(x=x, y=y, line=left_line, lower=lower_bound, upper=upper_bound)\n",
    "            mn, std = left_lookup[(lower_bound, upper_bound)]\n",
    "            if np.abs(d) <= 2*std:\n",
    "                not_outliers.append(idx)        \n",
    "\n",
    "cl_filter = cl[not_outliers, :]\n",
    "\n",
    "plt.plot(cl_filter[:,0], cl_filter[:,1], 'x')\n",
    "plt.errorbar(xl, yl, xerr=xl_err)\n",
    "plt.show()\n",
    "\n",
    "not_outliers = []\n",
    "for lower_bound, upper_bound in bounds:\n",
    "    for idx, point in enumerate(cr):\n",
    "        x, y = point\n",
    "        if lower_bound <= y <= upper_bound:\n",
    "            d = distance_from_line(x=x, y=y, line=right_line, lower=lower_bound, upper=upper_bound)\n",
    "            mn, std = left_lookup[(lower_bound, upper_bound)]\n",
    "            if np.abs(d) <= 2*std:\n",
    "                not_outliers.append(idx)        \n",
    "\n",
    "cr_filter = cr[not_outliers, :]\n",
    "\n",
    "plt.plot(cr_filter[:,0], cr_filter[:,1], 'x')\n",
    "plt.errorbar(xr, yr, xerr=xr_err)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Lane Parameters\n",
      "(445, 455) (1.7654389019814785, 13.014251636491556)\n",
      "(495, 505) (4.0217576521538563, 19.640978577514073)\n",
      "(345, 355) (-2.7527676764638689, 6.6038430374854373)\n",
      "(415, 425) (0.86863740324643979, 11.169631440690816)\n",
      "(435, 445) (2.0886860897085358, 11.586491048509149)\n",
      "(525, 535) (-2.8862164087219582, 24.378635632537172)\n",
      "(375, 385) (-2.4999758136848, 7.7889927537929982)\n",
      "(335, 345) (-8.7269854282211377, 14.352782040130313)\n",
      "(425, 435) (1.5492591952669006, 11.528540066674818)\n",
      "(485, 495) (4.4027231641529658, 15.996877302256351)\n",
      "(535, 545) (28.178816769922729, 31.376444133086018)\n",
      "(465, 475) (2.2967052537130854, 14.464701112871017)\n",
      "(405, 415) (-0.32155095668984562, 10.539267788287573)\n",
      "(475, 485) (3.9930917279096896, 16.104771661947805)\n",
      "(505, 515) (2.1787758492800546, 21.293251587720842)\n",
      "(515, 525) (2.4781165767449576, 20.937012569534105)\n",
      "(395, 405) (-1.3649112029282928, 9.3938820264493437)\n",
      "(355, 365) (-2.5930825937629813, 6.910713167969611)\n",
      "(385, 395) (-1.7064953706989565, 8.2255417485194187)\n",
      "(365, 375) (-2.9504919384957247, 7.1629879642505818)\n",
      "(455, 465) (1.2435230781497091, 13.093664488415051)\n",
      "Right Lane Parameters\n",
      "(445, 455) (-0.48022925468812977, 13.090561332311903)\n",
      "(495, 505) (0.39755247078271094, 17.8960739691416)\n",
      "(345, 355) (7.5231857919295022, 5.7692700179244252)\n",
      "(415, 425) (-0.48885011456118288, 10.366931469290055)\n",
      "(435, 445) (0.62960678550038707, 12.477495629304823)\n",
      "(525, 535) (-2.0088320235115726, 18.264734713279623)\n",
      "(375, 385) (0.078205037899023, 7.2028061575174123)\n",
      "(335, 345) (6.4434958809703442, 6.91058597907102)\n",
      "(425, 435) (-0.8585727936239701, 10.649552635375242)\n",
      "(485, 495) (-2.6785291076044344, 15.802025607522951)\n",
      "(535, 545) (4.1977418135924536, 25.752235659996142)\n",
      "(465, 475) (-1.1759359580322326, 14.564702320343365)\n",
      "(405, 415) (-0.37537720940566288, 9.5165934318488308)\n",
      "(475, 485) (-1.313016157253126, 14.250736035920632)\n",
      "(505, 515) (-2.7715634704288958, 17.201064359439812)\n",
      "(515, 525) (-1.8566997416447708, 18.419990779037985)\n",
      "(395, 405) (-0.030456473195944678, 8.2379060196110832)\n",
      "(355, 365) (4.5928231722752688, 6.8234309697133648)\n",
      "(385, 395) (0.50025522347004381, 8.3223819374343329)\n",
      "(365, 375) (1.3668401971450821, 7.1142240124144793)\n",
      "(455, 465) (-0.99975848266817413, 13.827591060767009)\n"
     ]
    }
   ],
   "source": [
    "# left lane parameters\n",
    "print(\"Left Lane Parameters\")\n",
    "for bound, parameters in left_lookup.items():\n",
    "    print(bound, parameters)\n",
    "\n",
    "# right lane parameters\n",
    "print(\"Right Lane Parameters\")\n",
    "for bound, parameters in right_lookup.items():\n",
    "    print(bound, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=10, show_originals=False):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    y_bin_size = 10\n",
    "    \n",
    "    l_lines = []\n",
    "    r_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            # compute slope\n",
    "            dx = x2 - x1\n",
    "            dy = y2 - y1\n",
    "            slope = dy/dx\n",
    "            \n",
    "            # compute center\n",
    "            center = x1 + dx/2, y1 + dy/2\n",
    "            \n",
    "            # left half of image\n",
    "            if center[0] <= 480:\n",
    "                if slope < -0.5:\n",
    "                    for lower_bound, upper_bound in left_lookup:\n",
    "                        if lower_bound <= center[1] < upper_bound:\n",
    "                            mn, std = left_lookup[(lower_bound, upper_bound)]\n",
    "                            d = distance_from_line(center[0], center[1], left_line, lower_bound, upper_bound)\n",
    "                            if np.abs(d) <= 2*std:\n",
    "                                if show_originals:\n",
    "                                    cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "                                l_lines.append(np.polyfit([x1, x2], [y1, y2], deg=1))\n",
    "            \n",
    "            # right half of image\n",
    "            else:\n",
    "                if slope > 0.4:\n",
    "                    for lower_bound, upper_bound in right_lookup:\n",
    "                        if lower_bound <= center[1] < upper_bound:\n",
    "                            mn, std = right_lookup[(lower_bound, upper_bound)]\n",
    "                            d = distance_from_line(center[0], center[1], right_line, lower_bound, upper_bound)\n",
    "                            if np.abs(d) <= 2*std:\n",
    "                                if show_originals:\n",
    "                                    cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "                                r_lines.append(np.polyfit([x1, x2], [y1, y2], deg=1))\n",
    "    \n",
    "    ll_params = np.array(l_lines)\n",
    "    left_slope, left_intercept = np.mean(ll_params[:,0]), np.mean(ll_params[:,1])\n",
    "    \n",
    "    x0, y0 = int(x_intercept(y_window['low'], left_slope, left_intercept)), int(y_window['low'])\n",
    "    xf, yf = int(x_intercept(y_window['high'], left_slope, left_intercept)), int(y_window['high'])\n",
    "    \n",
    "    cv2.line(img, (x0, y0), (xf, yf), color, thickness)\n",
    "    \n",
    "    rl_params = np.array(r_lines)\n",
    "    right_slope, right_intercept = np.mean(rl_params[:,0]), np.mean(rl_params[:,1])\n",
    "    \n",
    "    x0, y0 = int(x_intercept(y_window['low'], right_slope, right_intercept)), int(y_window['low'])\n",
    "    xf, yf = int(x_intercept(y_window['high'], right_slope, right_intercept)), int(y_window['high'])\n",
    "    \n",
    "    cv2.line(img, (x0, y0), (xf, yf), color, thickness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def hough_filter(img):\n",
    "    region = process_image(img)\n",
    "    lines = hough_lines(region, **hough_params)\n",
    "    return lines\n",
    "\n",
    "def overlay_lines(img):\n",
    "    lines = hough_filter(img)\n",
    "    return weighted_img(img, lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"test_images/whiteCarLaneSwitch.jpg\")\n",
    "region = process_image(img)\n",
    "lines = hough_lines(region, **hough_params)\n",
    "\n",
    "plt.imshow(lines)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:11<00:00, 19.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 30.8 s, sys: 860 ms, total: 31.7 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(overlay_lines) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:45<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 2min 2s, sys: 3.43 s, total: 2min 6s\n",
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(overlay_lines)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('left_lane_parameters.pickle', 'wb') as f:\n",
    "    pickle.dump(left_lookup, f)\n",
    "with open('right_lane_parameters.pickle', 'wb') as f:\n",
    "    pickle.dump(right_lookup, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  -0.69169104,  643.3071443 ])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_line.coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
